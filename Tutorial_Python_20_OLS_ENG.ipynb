{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = firebrick>Tutorial 20: Linear Regression using OLS <a id='home'></a>\n",
    "\n",
    "Welcome to this econometrics tutorial! Here, we will explore the basic models used in econometrics for analyzing economic data! So far, we have gathered several fundamental tools, and now it is time to apply them to understand economic relationships.\n",
    "\n",
    "Simply put, econometrics involves using statistical models to analyse economic data and draw conclusions. It doesn't matter if you're new to econometrics. We'll start with the basics, focusing on the tools and ideas you'll need to use Python for analysis. If you have some experience of econometrics, you will find that Python makes the application of these concepts easier and more interactive.\n",
    "\n",
    "In this course, we use statistical models to explain and predict relationships in data. We'll learn how to use statsmodels, a Python package specifically designed to build and estimate statistical models. You can explore its documentation here for reference: [docs](https://devdocs.io/statsmodels/).\n",
    "\n",
    "**In this tutorial**, we will explain:\n",
    "    \n",
    "- what is Ordinary Least Squares (OLS) regression\n",
    "- and how to use multivariate OLS regression\n",
    "\n",
    "Each section includes examples, explanations, and interactive Python code, so you can see exactly how econometrics tools apply in real economic contexts. Let‚Äôs get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Why OLS ? ([top](#home))<a id=\"math\"></a>\n",
    "\n",
    "To begin understanding econometrics, let‚Äôs frame a typical problem that economists encounter: identifying relationships between variables based on data from $ N $ observations. Suppose we are interested in a particular outcome or *explained variable*, which we‚Äôll call $ y $. We also have data on several other factors, called *explanatory variables*, which we think may help to explain $ y $. Let‚Äôs denote these explanatory variables as $ x_1, x_2, \\dots, x_p $.\n",
    "\n",
    "For example, suppose an economist wants to predict future movements in a stock market index, like the S&P 500. They might use variables like interest rates, inflation, or other economic indicators as part of $ X $ to explain $ y $, the index level. Here, the *prediction* is based on an econometric model that estimates the relationship between $ y $ and $ X $. This approach not only enables forecasts of $ y $ but also allows for interpretation, giving insights into *how* and *why* changes in economic factors influence the S&P 500.\n",
    "\n",
    "In econometrics, we assume that $ y $ is related to the $ x $ variables through a model we write as follows:\n",
    "\n",
    "$$\n",
    "y = f(X) + \\epsilon\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ y $ is the dependent variable, \n",
    "- $ X $ is the matrix of the explanatory variables,\n",
    "- $ f(.) $ is the function that represents the *systematic* or *structural* relationship between $ X $ and $ y$,\n",
    "- and $ \\epsilon $ is the *noise* or *error term* which accounts for the variation in $ y $ that isn‚Äôt explained by $ X $ alone.\n",
    "\n",
    "The primary goal in econometrics is to estimate $ f(.) $ which allows us to understand the relationship between $ y $ and $ X $. Estimating this relationship provides valuable insights into how changes in the explanatory variables impact the outcome. By analyzing this relationship, economists can also make predictions for $ y $ based on new values of $ X $.\n",
    "\n",
    "Let's clarify right now how we link each observation - our dataset - with this equation. Our goal here is to find an equation $ y = f(X) + \\epsilon$ that is designed to hold for each observation in our dataset. In other words, it means that this relationship holds for every individual observation $ i $, with $ i = 1, 2, \\dots, N $:\n",
    "\n",
    "$$\n",
    "y_i = f(x_{i1}, x_{i2}, \\dots, x_{ip}) + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ y_i $ is the observed value of the dependent variable for the $ i $-th observation,\n",
    "- $ x_{i1}, x_{i2}, \\dots, x_{ip} $ are the values of the explanatory variables for that $ i $-th observation,\n",
    "- and $ \\epsilon_i $ is the error term for that  $ i $-th observation.\n",
    "\n",
    "Now let's rewrite all these equations, each corresponding to an observation, into a single equation in matrix form. We assume that $ y $ is determined by a function $ f(X) $ of our explanatory variables plus some error term $ \\epsilon $, as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = f(\\mathbf{X}) + \\boldsymbol{\\epsilon}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_N \\\\\n",
    "\\end{pmatrix}\n",
    "=\n",
    "f \\left(\n",
    "\\begin{pmatrix}\n",
    "x_{11} & x_{12} & \\dots & x_{1p} \\\\\n",
    "x_{21} & x_{22} & \\dots & x_{2p} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{N1} & x_{N2} & \\dots & x_{Np} \\\\\n",
    "\\end{pmatrix}\n",
    "\\right)\n",
    "+\n",
    "\\begin{pmatrix}\n",
    "\\epsilon_1 \\\\\n",
    "\\epsilon_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\epsilon_N \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In this form:\n",
    "\n",
    "- The vector $\\mathbf{y}$ is a $ N \\times 1 $ vector of observed values,\n",
    "- The matrix $ \\mathbf{X} $ is a $ N \\times p $ matrix of explanatory variables, with each row corresponding to an observation.\n",
    "- The vector $ \\boldsymbol{\\epsilon} $ is the $ N \\times 1 $ vector of error terms for each observation.\n",
    "\n",
    "This matrix notation shows that each $ y_i $ is given by applying $ f $ to its corresponding row of $ \\mathbf{X} $ plus the error term $ \\epsilon_i $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Specifying the model\n",
    "\n",
    "How do we decide which variables to include in $ X $, or what form $ f $ should take? In econometrics, the choice of $ f $ and $ X $ is guided by research questions and academic results, and by the data available. \n",
    "\n",
    "For example, suppose we want to study the effect of online advertising spending on e-commerce sales. The dependent variable $y$ could represent monthly sales, while the explanatory variables $X$ might include advertising expenditures, website traffic, and customer demographics. If our goal is to estimate the causal effect of advertising, we need to ensure that advertising expenditures are appropriately included as part of $X$. Moreover, our model should allow us to interpret results meaningfully, such as estimating the advertising elasticity of demand. Understanding this relationship helps in decision-making, like optimizing digital marketing strategies.\n",
    "\n",
    "Here, we assume that the relationship between $y$ and $X$ is linear. Linear regression is chosen for its simplicity and interpretability, and because many complex relationships can be approximated or broken down into linear components, making it a multi-faceted starting point for modelling. This gives us the following data-generating process:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n",
    "$$\n",
    "\n",
    "where $ \\boldsymbol{\\beta} $ is a $ p \\times 1 $ vector of unknown parameters we aim to estimate.\n",
    "\n",
    "For each observation $j$ we then have:\n",
    "\n",
    "$$\n",
    "y_j = \\beta X_j + \\epsilon_j\n",
    "$$\n",
    "\n",
    "and in matrix form with all the observations:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \n",
    "    y_1 \\\\ \n",
    "    y_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    y_N\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "    \\beta_1 \\\\\n",
    "    \\beta_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\beta_p\n",
    "\\end{pmatrix} \n",
    "\\begin{pmatrix}\n",
    "    x_{11} & x_{12} & \\dots & x_{1p} \\\\\n",
    "    x_{21} & x_{22} & \\dots & x_{2p} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{N1} & x_{N2} & \\dots & x_{Np}\n",
    "\\end{pmatrix} + \n",
    "\\begin{pmatrix}\n",
    "    \\epsilon_1 \\\\\n",
    "    \\epsilon_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\epsilon_N\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "This allows you to easily find each individual equation from the matrix form.\n",
    "\n",
    "\n",
    "### A more practical example\n",
    "\n",
    "Suppose we have $ N $ observations of monthly sales ($ y $) for an online store and advertising expenditures ($ X $) on a popular social media platform. We hypothesize that advertising spending influences sales. To capture this relationship, we use the model:\n",
    "\n",
    "$$\n",
    "y_j = \\beta X_j + \\epsilon_j, \\quad j = 1, \\dots, N\n",
    "$$\n",
    "\n",
    "This equation reflects that sales $ y_j $ for each month $ j $ depend on advertising spend $ X_j $ scaled by the coefficient $ \\beta $ and a random error ($ \\epsilon_j $) capturing other factors affecting sales. \n",
    "\n",
    "By estimating $ \\beta $, we can answer questions like: How much does an additional dollar spent on advertising increase monthly sales? This provides actionable insights for businesses looking to optimize their advertising budgets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Monte Carlo simulation\n",
    "\n",
    "In general, for pedagogical reasons, we work with real data by assuming a functional form for $f$ and estimating the parameter $\\beta$. This assumption is necessary to make the model fit the observed data as closely as possible. However, if the assumed form of $f$ is incorrect, the estimates of $\\beta$ may be biased or inconsistent.\n",
    "\n",
    "To overcome this uncertainty, we take a different approach here by generating our own data using a true Data-Generating Process (DGP). In this case, we know the exact value of $\\beta$ and can directly evaluate how well our estimation method recovers it. This approach is called a Monte Carlo simulation and it allows us to test the performance and reliability of estimators under controlled conditions.\n",
    "\n",
    "\n",
    "**Python code**\n",
    "\n",
    "Execute the code below using \"Shift+Enter\". Explanations of the code are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np # Used for numerical operations (e.g., generating random numbers).\n",
    "import matplotlib.pyplot as plt # Used for plotting graphs.\n",
    "import seaborn as sea # Data visualization library built on Matplotlib (not used in the code).\n",
    "import pandas as pd # Used for data manipulation (not used in the code).\n",
    "\n",
    "\n",
    "# Create a local random generator with a fixed seed to ensure the same \"random\" numbers are generated each time we run this code.\n",
    "rng = np.random.default_rng(seed=10)\n",
    "\n",
    "# Set values\n",
    "beta = 1 # Coefficient for the independent variable X\n",
    "N = 100 # Number of observations or data points\n",
    "\n",
    "# Generate random N draws with an exponential distribution\n",
    "X = rng.exponential(1,size=N)\n",
    "\n",
    "# Generate random N draws with a normal distribution\n",
    "eps = rng.normal(0,1,size=N)\n",
    "\n",
    "# Determine Y\n",
    "Y = X * beta + eps\n",
    "\n",
    "# Create Figure\n",
    "fig, ax = plt.subplots(figsize=(10,5)) # Creates a figure and axis with specified size for the plot.\n",
    "\n",
    "ax.scatter(Y, X, alpha = 0.4, color='red') # Creates a scatter plot with X on the x-axis and Y on the y-axis, with some transparency (`alpha=0.4`) and red color for the points.\n",
    "\n",
    "ax.set_xlabel('Independent variable (X)', size=18) # Set the labels and title for the plot.\n",
    "ax.set_ylabel('Dependent variable (Y)', size=18)\n",
    "ax.set_title(r'$Y_j = \\beta X_j + \\epsilon_j,\\;\\beta$=' + str(beta), size=20)\n",
    "\n",
    "ax.spines['top'].set_visible(False) # Hide the top and right borders of the plot for a cleaner appearance.\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.show() # Displays the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python code explanation**\n",
    "\n",
    "1. **Setting the seed**:\n",
    "   - `np.random.default_rng(seed=10)`: This sets the seed for the random number generator to ensure reproducibility. When the code is run multiple times, it generates the same \"random\" numbers.\n",
    "\n",
    "2. **Generating random variables**:\n",
    "   - `X = rng.exponential(1,size=N)`: Generates `N` random draws from an exponential distribution with a mean of 1. These are the values for the independent variable $X$.\n",
    "   - `eps = rng.normal(0,1,size=N)`: Generates `N` random draws from a normal distribution with mean 0 and standard deviation 1. These are the error terms $\\epsilon$.\n",
    "\n",
    "4. **Calculating the dependent variable**:\n",
    "   - `Y = X * beta + eps`: The dependent variable $Y$ is determined by the formula $Y = \\beta X + \\epsilon$, where $\\beta = 1$.\n",
    "\n",
    "**Why do we fix a random seed?**\n",
    "\n",
    "In simulations, random numbers are used to generate artificial data. If we don‚Äôt fix the random seed, the data will change every time we run the code ‚Äî meaning the results will also change. By setting a seed with `np.random.default_rng(seed=10)`), we make sure that:\n",
    "- the same random numbers are generated each time,\n",
    "- results are reproducible,\n",
    "- we can debug and compare models fairly.\n",
    "\n",
    "This is especially important in econometrics and Monte Carlo simulations, where we want to see how models behave ‚Äî not how random noise changes.\n",
    "\n",
    "Next, to better understand how the code works, you can print the different variables generated by the code and view their contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rng)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eps)\n",
    "print(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link with matrix notation\n",
    "\n",
    "The Python code generates synthetic data for the linear regression model:\n",
    "$$\n",
    "Y_j = \\beta X_j + \\epsilon_j \\quad \\text{for } j = 1, \\dots, N\n",
    "$$\n",
    "where:\n",
    "- $ Y_j $ is the dependent variable.\n",
    "- $ X_j $ is the independent variable.\n",
    "- $ \\beta $ is the coefficient (set to 1 in this example).\n",
    "- $ \\epsilon_j $ is the random error term, drawn from a normal distribution $ \\mathcal{N}(0, 1) $.\n",
    "\n",
    "\n",
    "\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Python Code} & \\textbf{Matrix Notation} & \\textbf{Python Object} & \\textbf{Explanation} \\\\\n",
    "\\hline\n",
    "X = rng.exponential(1,size=N) & X \\sim \\text{Exponential}(1) & \\text{List of size } N & \\text{Generate } X \\\\\n",
    "\\hline\n",
    "\\epsilon = rng.normal(0,1,size=N) & \\epsilon \\sim \\mathcal{N}(0, 1) & \\text{List of size } N & \\text{Generate noise } \\epsilon \\\\\n",
    "\\hline\n",
    "Y = \\beta \\cdot X + \\epsilon & Y = X \\beta + \\epsilon & \\text{List of size } N & \\text{Compute } Y \\\\\n",
    "\\hline\n",
    "\\texttt{ax.scatter(Y, X, ...)} & \\text{Scatter plot} & \\text{N/A} & \\text{Visualize } X \\text{ vs. } Y \\\\\n",
    "\\hline\n",
    "\\texttt{ax.set\\_title(...)} & Y_j = \\beta X_j + \\epsilon_j, \\; \\beta = 1 & \\text{N/A} & \\text{Set plot title} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Interpretation of the generated plot\n",
    "\n",
    "The scatter plot shows the generated data points. The independent variable $ X $ (on the x-axis) has been drawn from an exponential distribution and the dependent variable $ Y $ (on the y-axis) is a linear function of $ X $ with added random noise $ \\epsilon $.\n",
    "\n",
    "This visualization demonstrates how randomness in $ \\epsilon $ creates variation in $ Y $, even when the relationship with $ X $ is linear.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We present below the equivalent of this code in Stata and R.**\n",
    "\n",
    "We present below the equivalents of this code for Stata and R. You are invited to click on the two texts below to discover the codes, read the explanations and test them in Stata and R. You can then compare these codes with the Python code. Note the similarities and differences between the three languages.\n",
    "\n",
    "### Stata code\n",
    "\n",
    "<details>\n",
    "<summary>-- Click here to see the Stata code --</summary>\n",
    "\n",
    "**Running code in Stata**\n",
    "\n",
    "To run the code in **Stata** using Stata software, follow these steps:\n",
    "\n",
    "1. **Open Stata**: Launch Stata\n",
    "2. **Enter the Command Window**:\n",
    "   - You can type commands directly in the **Command Window** in Stata.\n",
    "3. **Copy and Paste the Code**:\n",
    "   - Copy the Stata code (provided below).\n",
    "   - Paste it into the **Command Window** in Stata.\n",
    "4. **Execute the Code**:\n",
    "   - Press **Enter** after pasting the code. Stata will execute the code and display results in the **Results Window**.\n",
    "\n",
    "\n",
    "You can also save this code in a **do-file** for later execution:\n",
    "- In Stata, go to File > New Do-file or use the Do-file Editor.\n",
    "- Paste your code into the Do-file.\n",
    "- Save the file (e.g., my_analysis.do).\n",
    "- In the Command Window, run the code by typing: do my_analysis.do and press Enter.\n",
    "\n",
    "**Stata code** \n",
    "```stata\n",
    "set seed 10\n",
    "\n",
    "* Set values\n",
    "local beta 1\n",
    "local N 100\n",
    "\n",
    "* Generate random draws for X and eps\n",
    "gen X = rexp(1) in 1/`N'\n",
    "gen eps = rnormal(0,1) in 1/`N'\n",
    "\n",
    "* Calculate Y\n",
    "gen Y = `beta' * X + eps\n",
    "\n",
    "* Scatter plot\n",
    "twoway (scatter Y X, mcolor(red) msymbol(O) msize(medium)) ///\n",
    "       , xlabel(, size(18)) ylabel(, size(18)) title(\"$Y_j = \\beta X_j + \\epsilon_j, \\;\\beta=\" + string(`beta')) size(20)\n",
    "```\n",
    "\n",
    "**Stata code explanation**\n",
    "\n",
    "- ``gen X = rexp(1) in 1/`N'``: Generates $N$ random draws from an exponential distribution.\n",
    "- ``gen eps = rnormal(0,1) in 1/`N'``: Generates $N$ random draws from a normal distribution with mean 0 and standard deviation 1.\n",
    "- ``twoway scatter`: Plots $ùëå$ against $X$ with red circles as markers (``mcolor(red)`).\n",
    "- The ``xlabel()``, ``ylabel()``, and ``title()`` options adjust the appearance of the plot, including the labels and title.\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "### R code\n",
    "\n",
    "<details>\n",
    "<summary>-- Click here to see the R code --</summary>\n",
    "\n",
    "\n",
    "\n",
    "**Running code in R using RStudio**\n",
    "\n",
    "To run the code in R using RStudio, follow these steps:\n",
    "\n",
    "1. **Open RStudio:** Launch RStudio\n",
    "2. Go to File > New File > R Script or press Ctrl + Shift + N to open a new R script.\n",
    "3. Copy-paste the R code into the R script in the RStudio editor.\n",
    "4. Run the Code:\n",
    "- Highlight the code you want to run.\n",
    "- Press Ctrl + Enter (Windows/Linux) or Cmd + Enter (Mac) to execute the selected code in the Console.\n",
    "\n",
    "Alternatively, you can click on the Run button at the top of the script editor to execute the entire script.\n",
    "\n",
    "**R code** \n",
    "```\n",
    "# R code example\n",
    "set.seed(10)\n",
    "\n",
    "# Set values\n",
    "beta <- 1\n",
    "N <- 100\n",
    "\n",
    "# Generate random draws for X and eps\n",
    "X <- rexp(N, rate = 1)\n",
    "eps <- rnorm(N, mean = 0, sd = 1)\n",
    "\n",
    "# Calculate Y\n",
    "Y <- beta * X + eps\n",
    "\n",
    "# Create a scatter plot with equation in title\n",
    "plot(X, Y, col = \"red\", pch = 16, \n",
    "     xlab = \"Independent Variable (X)\", \n",
    "     ylab = \"Dependent Variable (Y)\", \n",
    "     main = expression(paste(\"Y[j] = \", beta, \" * X[j] + epsilon[j], \", beta, \" = \", 1)))\n",
    "```\n",
    "\n",
    "\n",
    "**R code explanation**\n",
    "\n",
    "- ``X <- rexp(N, rate = 1)``: Generates N random draws from an exponential distribution.\n",
    "- ``eps <- rnorm(N, mean = 0, sd = 1)``: Generates N random draws from a normal distribution.\n",
    "- ``Y <- beta * X + eps``: Calculates the dependent variable $Y$.\n",
    "- ``plot()``: Creates the scatter plot with red points (``col = \"red\"``), adjusted point size (``pch = 16``), axis labels, and the plot title that includes the value of $\\beta$.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Task #1:</font> Analyze the Impact of $\\beta$ on the Data-Generating Process (DGP)\n",
    "\n",
    "Modify the value of $\\beta$ to 0.5, 2, and 5 in the code, and re-run the code for each value of $\\beta$.\n",
    "\n",
    "1. How does $\\beta$ affect the slope of the relationship between $ùëã$ (independent variable) and $ùëå$ (dependent variable)?\n",
    "2. Does increasing $\\beta$ make the observations more spread out or closer together? Why?\n",
    "\n",
    "<details>\n",
    "<summary>-- Click here to see the answer --</summary>\n",
    "    \n",
    "1. **How does $\\beta$ affect the slope?**\n",
    "\n",
    "$\\beta$ is the slope of the deterministic part of the Data-Generating Process (DGP). If we change $\\beta$, we scale the systematic relationship between $X$ and $Y$. A larger $\\beta$ means a steeper slope, while a smaller $\\beta$ means a flatter slope. Graphically, the regression line $Y = \\beta X$ rotates around the origin (in our simple model with no intercept).\n",
    "\n",
    "2. **Does increasing $\\beta$ make observations more spread out or closer?**\n",
    "\n",
    "The variance of $Y$ is (assuming $X$ and $\\varepsilon$ are independent):\n",
    "\n",
    "$$\n",
    "Var(Y)=Var(\\beta X + \\epsilon)= \\beta^2 Var(X)+Var(\\epsilon)\n",
    "$$.\n",
    "\n",
    "As $|\\beta|$ increases, the term $\\beta^2 Var (X)$ grows, so the total variance of $Y$ increases ‚Äî the observations become more spread out vertically. Intuitively, scaling the systematic part $\\beta X$ stretches the cloud of points along the $Y$-axis. The noise term $\\varepsilon$ remains the same but its relative importance diminishes when $\\beta$ is large.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Estimator $\\hat{\\beta}$\n",
    "Since we assume that the relationship between $Y$ and $X$ is linear through $f$, this means that we want to draw a line that passes through the data points starting from the origin. We want this line to pass through as many data points as possible. Intuitively, you can think of placing a ruler at the point $(0,0)$ and rotating it until the line seems to capture the overall trend of the data ‚Äî we will now formalize this idea mathematically.\n",
    "\n",
    "In Ordinary Least Squares (OLS), the ‚Äúbest‚Äù line is the one that minimizes the total squared distance between the observed points and the predicted values ‚Äî these vertical distances are called *residuals*. The optimization problem is therefore:\n",
    "$$\n",
    "\\min_{\\beta} \\sum_j \\left[ Y_j - \\underbrace{(X_j \\beta)}_{\\text{Predicted value}} \\right]^2\n",
    "$$\n",
    "where:\n",
    "- $Y_j$ is the dependent variable for observation $j$,\n",
    "- $X_j$ is the independent variable (or vector of regressors),\n",
    "- $\\beta$ is the parameter (or vector of parameters) to be estimated,\n",
    "- and $\\left[Y_j - X_j \\beta\\right]$ is the residual, denoted $\\hat{\\varepsilon}_j$.\n",
    "\n",
    "In the underlying population model, we assume that\n",
    "$\n",
    "Y_j = X_j \\beta + \\varepsilon_j,\n",
    "$\n",
    "where $\\varepsilon_j$ is the *true* (unobserved) error term that captures all factors affecting $Y_j$ other than $X_j$. It represents the difference between the actual and predicted values for each observation.\n",
    "\n",
    "  \n",
    "The OLS method ‚Äî *Ordinary Least Squares* ‚Äî thus finds the value of $\\beta$ that minimizes the **sum of squared residuals**, producing the line that best fits the data in the least-squares sense. The term *‚Äúordinary‚Äù* simply refers to this being the most basic and widely used version of least-squares estimation. In other words, we estimate the parameter $\\beta$ that defines the slope of the regression line so that the total squared distance between the data points and the fitted line is as small as possible.\n",
    "\n",
    "**Why minimize the squared errors?**\n",
    "\n",
    "Squaring the error ensures we're indifferent between overestimation and underestimation, and penalizes larger errors more. Summing the squared errors across all data points gives the total error. To find $\\beta$ that minimizes the error, we take the derivative of the sum with respect to $\\beta$ and set it equal to zero (FOC):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\beta} \\sum_j \\left[ Y_j - X_j \\beta \\right]^2= \n",
    "-2\\sum_j X_j\\left[ Y_j - X_j \\beta \\right] = 0\n",
    "$$\n",
    "\n",
    "Re-arranging this expression, we get:\n",
    "\n",
    "$$\n",
    "\\sum_j X_j Y_j - \\beta \\sum_j X_j^2 = 0 \\Longrightarrow \\quad \\boxed{\\hat{\\beta} = \\frac{\\sum_j  X_j Y_j}{\\sum_j X_j^2}}\n",
    "$$\n",
    "\n",
    "Then, we can substitute $Y_j = \\beta X_j + \\varepsilon_j$, which gives:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}\n",
    "= \\frac{\\sum_j X_j(\\beta X_j + \\varepsilon_j)}{\\sum_j X_j^2}\n",
    "= \\beta + \\frac{\\sum_j X_j \\varepsilon_j }{\\sum_j X_j^2}.\n",
    "$$\n",
    "\n",
    "We deduce from this the estimation error:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} - \\beta = \\frac{\\sum_j X_j \\varepsilon_j }{\\sum_j X_j^2}.\n",
    "$$\n",
    "\n",
    "\n",
    "To ensure that $\\hat{\\beta}$ is unbiased, we assume the **zero conditional mean** condition:\n",
    "\n",
    "$$\n",
    "\\forall j \\quad  \\mathbb{E}[\\varepsilon_j \\mid X_j] = 0.\n",
    "$$\n",
    "\n",
    "This assumption says that the expected value of the error term given $X_j$ is zero. Thus knowing $X_j$ tells us nothing systematic about the error term. That means there is no systematic relationship between $X_j$ and $\\varepsilon_j$.\n",
    "\n",
    "\n",
    "Under this assumption, and using the law of total expectation ($\\mathbb{E}[X_j \\varepsilon_j ]\n",
    "= \\mathbb{E}\\!\\left[\\mathbb{E}[X_j\\varepsilon_j \\mid X_j]\\right]$), we have:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\!\\left[\\sum_j X_j \\varepsilon_j \\right]\n",
    "= \\sum_j \\mathbb{E}[X_j \\varepsilon_j ]\n",
    "= \\sum_j \\mathbb{E}\\!\\left[\\mathbb{E}[X_j\\varepsilon_j \\mid X_j]\\right]\n",
    "= \\sum_j \\mathbb{E}\\!\\left[X_j\\,\\mathbb{E}[\\varepsilon_j \\mid X_j]\\right]\n",
    "= 0.\n",
    "$$\n",
    "\n",
    "Hence, $\\mathbb{E}[\\hat{\\beta}] = \\beta$, meaning $\\hat{\\beta}$ is an unbiased estimator of $\\beta$. Overall, we have shown:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\hat{\\beta} = \\frac{\\sum_j X_jY_j}{\\sum_j X_j^2}\n",
    "= \\beta + \\frac{\\sum_j X_j\\varepsilon_j}{\\sum_j X_j^2}\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "**Remark** Assuming independence between $X_j$ and $\\varepsilon_j$\n",
    "(i.e., $\\mathbb{E}[X_j\\varepsilon_j] = \\mathbb{E}[X_j]\\mathbb{E}[\\varepsilon_j]$)\n",
    "is stronger than necessary. The zero conditional mean assumption\n",
    "$\\mathbb{E}[\\varepsilon_j \\mid X_j] = 0$\n",
    "is sufficient and standard in econometrics.\n",
    "\n",
    "Now, here's the key insight: we've assumed that $\\epsilon_j$ represents random noise. Since this noise is random, it cannot be correlated with $X$, that is $ X_j $ and $ \\epsilon_j $ are independent and $ E(X_j \\epsilon_j) = E(X_j) \\cdot E(\\epsilon_j) $. Given that $ E(\\epsilon_j) = 0 $, we have $ E\\left(\\sum_j X_j \\epsilon_j\\right) = \\sum_j 0 = 0 $. It means that the term $\\sum_j X_j \\epsilon_j$ will be zero in expectation (or close to zero when the number of observations is large).\n",
    "\n",
    "\n",
    "We can verify this result using the graph below. On the graph, the scatter points represent the actual data points $(X_j, Y_j)$ on the graph. The blue line is the best fit line that minimizes the total squared distance between the data points and the line, which is the line of predicted values. The residuals are the vertical distances between the scatter points and the regression line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numerator = np.sum(Y*X)\n",
    "denominator = np.sum(X*X)\n",
    "bhat = numerator/denominator\n",
    "\n",
    "Yhat = X*bhat \n",
    "\n",
    "# Create Figure\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.scatter(Y,X, alpha = 0.4, color = 'red')\n",
    "ax.plot(Yhat,X, color = 'blue')\n",
    "\n",
    "ax.set_xlabel('Independent variable (X)')\n",
    "ax.set_ylabel('Dependent variable (Y)')\n",
    "ax.set_title(r'Proposed DGP with $\\beta$='+str(beta),size=20)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.annotate(fr'$\\hat\\beta=${bhat:.2f}', (2.2,3.5),size=16, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python code explanation**\n",
    "- ``numerator = np.sum(Y * X)``: This calculates the sum of the product of the observed values of Y and X, which is used in calculating the estimate for $\\hat{\\beta}$.\n",
    "- ``denominator = np.sum(X * X)``: This calculates the sum of the squares of X, which is part of the denominator for calculating $\\hat{\\beta}$\n",
    "- ``bhat = numerator / denominator``: This divides the sum of products by the sum of squares to get the estimated value of $\\hat{\\beta}$, which minimizes the least squares error.\n",
    "- ``Yhat = X * bhat``: This computes the predicted values of Y using the estimated $\\hat{\\beta}$.\n",
    "\n",
    "The code uses Matplotlib to create a scatter plot of the data points (Y vs X) in red with a transparency of 0.4 (alpha = 0.4). It then plots the estimated regression line (Yhat vs X) in blue. Labels for the axes and title are set, and the top and right spines are removed for a cleaner plot.\n",
    "Annotation:\n",
    "\n",
    "The code annotates the plot with the estimated $\\hat{\\beta}$ value at coordinates (2.2, 3.5).\n",
    "\n",
    "### Link with matrix notation\n",
    "\n",
    "We propose here to connect the Python code to the matrix notation by explaining the key calculations in the mathematical framework of linear regression. The relationship between the dependent variable \\( Y \\) and the independent variable \\( X \\) in matrix form is given by:\n",
    "$$\n",
    "Y = X \\beta + \\epsilon\n",
    "$$\n",
    "where:\n",
    "- $ Y $ is the $ N \\times 1 $ vector of observed dependent variables.\n",
    "- $ X $ is the $ N \\times p $ matrix of independent variables (in your example, \\( X \\) is a column vector since there is one independent variable).\n",
    "- $ \\beta $ is the $ p \\times 1 $ vector of coefficients to be estimated.\n",
    "- $ \\epsilon $ is the $ N \\times 1 $ vector of residuals (errors).\n",
    "\n",
    "The ordinary least squares (OLS) estimate for $ \\beta $ is:\n",
    "$$\n",
    "\\hat{\\beta} = \\frac{X^\\top Y}{X^\\top X}\n",
    "$$\n",
    "This formula minimizes the sum of squared errors.\n",
    "\n",
    "### Mapping to the Python code\n",
    "\n",
    "1. **Calculate $\\hat{\\beta}$:**\n",
    "   - The numerator in the code, `np.sum(Y * X)`, corresponds to $ X^\\top Y $, the inner product of $ X $ and $ Y $.\n",
    "   - The denominator, `np.sum(X * X)`, corresponds to $ X^\\top X $, the inner product of $ X $ with itself.\n",
    "   - The division `numerator / denominator` gives $ \\hat{\\beta} $, the estimated coefficient.\n",
    "\n",
    "2. **Predict $ Y $:**\n",
    "   - `Yhat = X * bhat` calculates the predicted values, corresponding to $ \\hat{Y} = X \\hat{\\beta} $.\n",
    "\n",
    "3. **Plot the Data and Model:**\n",
    "   - The scatter plot visualizes the data points ($ Y $ vs. $ X $).\n",
    "   - The line plot shows the fitted regression line ($ \\hat{Y} $ vs. $ X $).\n",
    "\n",
    "4. **Annotation:**\n",
    "   - The annotation in the plot highlights the estimated $ \\hat{\\beta} $ value, providing a numerical summary of the slope of the regression line.\n",
    "\n",
    "### Python code and matrix notation side-by-side\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "    \\hline \\textbf{Python code} & \\textbf{Matrix notation} & \\textbf{Python Object} & \\textbf{Explanation} \\\\ \n",
    "    \\hline\n",
    "    \\texttt{numerator = np.sum(Y * X)} & X^\\top Y & \\texttt{float} &  \\text{Inner product of } X \\text{ and } Y \\\\\n",
    "    \\hline\n",
    "    \\texttt{denominator = np.sum(X * X)} & X^\\top X & \\texttt{float}  & \\text{Inner product of } X \\text{ with itself} \\\\\n",
    "    \\hline\n",
    "    \\texttt{bhat = numerator / denominator} & \\hat{\\beta} = \\frac{X^\\top Y}{X^\\top X} & \\texttt{float}  & \\text{Estimate the coefficient minimizing } \\\\\n",
    "    &  & & \\text{the least squares error}  \\\\\n",
    "    \\hline\n",
    "    \\texttt{Yhat = X * bhat} & \\hat{Y} = X \\hat{\\beta} & \\texttt{numpy.ndarray} (size N)  & \\text{Predicted values using the estimated } \\hat{\\beta} \\\\\n",
    "    \\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stata code\n",
    "\n",
    "<details>\n",
    "<summary>*Click here to see the Stata code*</summary>\n",
    "\n",
    "```\n",
    "* Set seed for reproducibility\n",
    "set seed 10\n",
    "\n",
    "* Define parameters\n",
    "local beta = 1\n",
    "local N = 100\n",
    "\n",
    "* Generate data\n",
    "gen X = exp(runiform())\n",
    "gen eps = rnormal(0, 1)\n",
    "gen Y = `beta' * X + eps\n",
    "\n",
    "* Estimate beta\n",
    "gen bhat = sum(Y * X) / sum(X * X)\n",
    "gen Yhat = X * bhat\n",
    "\n",
    "* Plotting\n",
    "scatter Y X, mcolor(red) msymbol(o) msize(0.5) xlabel(, grid) ylabel(, grid)\n",
    "line Yhat X, lcolor(blue) \n",
    "text 2.2 3.5 \"Œ≤ÃÇ = \" + string(bhat, \"%9.2f\"), color(blue) size(medium)\n",
    "```\n",
    "\n",
    "**Stata code explanation**\n",
    "\n",
    "- ``gen X = exp(runiform()``: Generates N random values from an exponential distribution for X.\n",
    "- ``gen eps = rnormal(0, 1)``: Generates N random errors (residuals) from a normal distribution.\n",
    "- ``gen Y = \\beta'*X + eps``: Calculates Y as the dependent variable in the model $Y = \\beta X + \\epsilon$\n",
    "- ``gen bhat = sum(Y * X) / sum(X * X)``: Computes the estimated $\\hat{\\beta}$.\n",
    "- ``gen Yhat = X * bhat``: Calculates the predicted Y values using the estimated $\\hat{\\beta}$.\n",
    "- ``scatter Y X``: Creates a scatter plot with red dots.\n",
    "- ``line Yhat X``: Plots the regression line.\n",
    "- ``text``...: Annotates the plot with the estimated $\\hat{\\beta}$.\n",
    "\n",
    "</details>\n",
    "    \n",
    "\n",
    "### R code\n",
    "\n",
    "<details>\n",
    "<summary>*Click here to see the Stata code*</summary>\n",
    "\n",
    "    \n",
    "```\n",
    "# Set seed for reproducibility\n",
    "set.seed(10)\n",
    "\n",
    "# Define parameters\n",
    "beta <- 1\n",
    "N <- 100\n",
    "\n",
    "# Generate data\n",
    "X <- rexp(N, rate = 1)\n",
    "eps <- rnorm(N, mean = 0, sd = 1)\n",
    "Y <- beta * X + eps\n",
    "\n",
    "# Estimate beta\n",
    "numerator <- sum(Y * X)\n",
    "denominator <- sum(X * X)\n",
    "bhat <- numerator / denominator\n",
    "Yhat <- X * bhat\n",
    "\n",
    "# Plotting\n",
    "plot(X, Y, pch = 16, col = rgb(1, 0, 0, alpha = 0.4), xlab = \"Independent Variable (X)\", \n",
    "     ylab = \"Dependent Variable (Y)\", main = paste(\"Proposed DGP with Œ≤ =\", beta))\n",
    "lines(X, Yhat, col = \"blue\")\n",
    "text(2.2, 3.5, paste(\"Œ≤ÃÇ =\", round(bhat, 2)), col = \"blue\", cex = 1.5)\n",
    "\n",
    "```\n",
    "\n",
    "**R code explanation**\n",
    "\n",
    "- ``X <- rexp(N, rate = 1)``: Generates N random values from an exponential distribution for the independent variable X.\n",
    "- ``eps <- rnorm(N, mean = 0, sd = 1)``: Generates N random errors (residuals) from a normal distribution.\n",
    "- ``Y <- beta * X + eps``: Calculates the dependent variable Y based on the model $Y = \\beta X + \\epsilon$.\n",
    "Estimate Beta ($\\hat{\\beta}$):\n",
    "\n",
    "- ``numerator <- sum(Y * X)``: Calculates the sum of the product of the observed values of Y and X.\n",
    "- ``denominator <- sum(X * X)``: Calculates the sum of the squares of X.\n",
    "- ``bhat <- numerator / denominator``: Calculates the estimated $\\hat{\\beta}$.\n",
    "- ``plot(X, Y, ...)``: Creates a scatter plot with transparency (alpha = 0.4) for better visualization.\n",
    "- ``lines(X, Yhat, col = \"blue\")``: Plots the regression line.\n",
    "- ``text(2.2, 3.5, ...)``: Adds the estimated value of $\\hat{\\beta}$ on the plot.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Task #2:</font> Standardize $ùëã$\n",
    "We want to standardize the $X$ values before calculating $Y$. We replace the original $ùëã$ with its standardized version:\n",
    "$$\n",
    "    X_{standard.}= \\frac{X-\\text{mean}(X)}{\\text{std}(X)}\n",
    "$$\n",
    " \n",
    "Implement this transformation in the code:\n",
    "```\n",
    "X_standardized = (X - np.mean(X)) / np.std(X)\n",
    "```\n",
    "\n",
    "Re-run the code with the standardized $ùëã$, and compare the scatter plot and title to the original $X$.\n",
    "\n",
    "1. How does standardizing $X$ affect the interpretation of $\\beta$?\n",
    "2. Does the distribution of $Y$ change? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Variance of our estimate\n",
    "Our estimate of $\\beta$ is accurate, but it's not exactly the true value. Why? Recall that earlier we assumed the interaction between $X$ and $\\epsilon$ to be zero in expectation. If this assumption is not true, then $\\hat{\\beta}$ will be incorrect. Thus, our estimate of $\\beta$ is an approximation and we want to understand the **variance** of this estimate to quantify the uncertainty.\n",
    "\n",
    "### Variance of $\\hat{\\beta}$\n",
    "\n",
    "The variance of $\\hat{\\beta}$ is defined as:\n",
    "\n",
    "$$\n",
    "V(\\hat{\\beta}) = \\frac{1}{N} \\sum_j \\left[ (\\beta - \\hat{\\beta}) X_j \\right]^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $N$ is the number of observations,\n",
    "- $X_j$ is the observed value of the independent variable for observation $j$,\n",
    "- $\\hat{\\beta}$ is the estimated coefficient,\n",
    "- and $\\beta$ is the true value of the coefficient (which we are trying to estimate).\n",
    "\n",
    "It measures the spread of the estimated values of $\\hat{\\beta}$ around the true value, reflecting the uncertainty in our estimate.\n",
    "\n",
    "From the Ordinary Least Squares (OLS) estimation, we know that:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{\\beta} = \\beta + \\frac{\\sum_j \\epsilon_j  X_j}{\\sum_j X_j^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "which we replace in the variance formula:\n",
    "$$\n",
    "V(\\hat{\\beta}) = \\frac{1}{N} \\sum_j \\left[ \\frac{\\sum_k \\epsilon_k  X_k}{\\sum_k X_k^2}. X_j \\right]^2 = \\frac{1}{N} \\left[ \\frac{\\sum_k \\epsilon_k  X_k}{\\sum_k X_k^2} \\right]^2 \\sum_j X_j^2 = \\frac{1}{N}  \\frac{\\left[\\sum_k \\epsilon_k  X_k\\right]^2}{\\sum_k X_k^2} \n",
    "$$\n",
    "\n",
    "This simplifies to:\n",
    "\n",
    "$$\n",
    "V(\\hat{\\beta}) = \\frac{\\sigma^2}{\\sum_j X_j^2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "-  $\\sigma^2$ represents the variance of the error term $\\epsilon_j$, which measures the spread or variability of the errors around the regression line.\n",
    "- $\\sum_j X_j^2$ is the sum of the squared values of the independent variable $X_j$, which reflects the variation or spread of the independent variable itself.\n",
    "\n",
    "This simplification shows that the variance of the estimated $\\beta$ depends on the variability in both the error term $\\epsilon_j$and the independent variable $X$. Higher variability in $X$ reduces the variance of $\\hat{\\beta}$, making the estimate more precise. The $\\sigma^2$ represents the inherent noise in the system (how much the errors vary), which impacts the precision of our estimate of $\\beta$.\n",
    "\n",
    "In OLS, $\\sigma^2$ represents the variance of the error term $\\epsilon_j$. Since we don't know the true errors \n",
    "$\\epsilon_j$, we approximate $\\sigma^2$ by calculating the variance of the residuals, which are our best estimate of the errors:\n",
    "$$\\sigma^2 = \\frac{\\sum_j \\epsilon_j^2}{N - p}$$\n",
    "\n",
    "with $p$ being the number of parameters estimated.\n",
    "\n",
    "The term $N - p$ represents the degrees of freedom. Since we don't know the true $\\epsilon$, we estimate it and use the estimated $\\hat{\\epsilon}$ for the calculation. Thus, the estimated variance of $\\hat{\\beta}$ is:\n",
    "\n",
    "$$\n",
    "V(\\hat{\\beta}) = \\frac{\\sum_j \\hat{\\epsilon}_j^2}{\\sum_j X_j^2}\n",
    "$$\n",
    "\n",
    "where $\\epsilon_j$ is approximated by the residuals $\\hat{\\epsilon}_j=Y_j-\\hat{Y}_j$. This expression effectively \"averages\" the squared residuals, with the adjustment for the number of estimated parameters.\n",
    "\n",
    "### Standard error and t-test\n",
    "\n",
    "The **standard error** (SE) of $\\hat{\\beta}$ is the square root of its variance:\n",
    "\n",
    "$$\n",
    "\\text{SE}(\\hat{\\beta}) = \\sqrt{V(\\hat{\\beta})}\n",
    "$$\n",
    "\n",
    "To test whether $\\hat{\\beta}$ is significantly different from a null hypothesis (often $\\beta_0 = 0$, meaning no relationship between $X$ and $Y$), we use a **t-test**:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\hat{\\beta} - \\beta_0}{\\text{SE}(\\hat{\\beta})} \\sim T_{N - p}\n",
    "$$\n",
    "\n",
    "where $T_{N - p}$ represents the T-distribution with $N - p$ degrees of freedom. A commonly used rule of thumb is that for a t-statistic greater than 2, we can reject the null hypothesis with 95% confidence.\n",
    "\n",
    "In practice, we often report the **standard errors** because they allow us to compute t-statistics for different null hypotheses.\n",
    "\n",
    "**What is a T-distribution?**\n",
    "\n",
    "The **T-distribution** is a probability distribution that arises when estimating the mean of a normally distributed population with small sample sizes and unknown population variance. It resembles the standard normal distribution but has heavier tails, accounting for greater variability in small samples. As the sample size increases, the T-distribution aHpproaches the standard normal distribution.\n",
    "\n",
    "Key characteristics:\n",
    "-  The shape of the T-distribution depends on the \\textbf{degrees of freedom (df)}, calculated as $ df = N - p$ where $N$ is the sample size and $p$ is the number of parameters estimated.\n",
    "- With more degrees of freedom, the T-distribution converges to the standard normal distribution.\n",
    "\n",
    "**How to apply a t-test in practice?**\n",
    "\n",
    "The **t-test** is used to determine if an estimated coefficient or sample mean differs significantly from a hypothesized value (null hypothesis). The steps to apply it are:\n",
    "\n",
    "1. Set up the null and alternative hypotheses:\n",
    "    - null hypothesis: $(H_0): \\beta = \\beta_0$\n",
    "    - alternative hypothesis: $(H_1): \\beta \\neq \\beta_0$ (two-tailed test) or $ \\beta > \\beta_0$, $\\beta < \\beta_0$ (one-tailed test)\n",
    "\n",
    "2. Compute the t-statistic:\n",
    "    $$\n",
    "    t = \\frac{\\hat{\\beta} - \\beta_0}{\\text{SE}(\\hat{\\beta})},\n",
    "    $$\n",
    "    where $\\hat{\\beta}$ is the estimated coefficient, $\\beta_0$ is the hypothesized value under $H_0$ (often 0), and $\\text{SE}(\\hat{\\beta})$ is the standard error of $\\hat{\\beta}$.\n",
    " \n",
    "3. Determine the critical value or p-value:\n",
    "    - For a two-tailed test at the $95\\%$ confidence level, compare $|t|$ to the critical value $t^*$ from the T-distribution table with $df = N - p$.\n",
    "    - Alternatively, compute the p-value and compare it to the significance level ($\\alpha$, typically 0.05).\n",
    "\n",
    "4. Make a decision: if $|t| > t^*$ (critical value), or $p < \\alpha$, reject $H_0$, otherwise, fail to reject $H_0$.\n",
    "\n",
    "**Example with numbers**\n",
    "\n",
    "Suppose we estimate the regression coefficient $\\hat{\\beta} = 1.2$ with a standard error $\\text{SE}(\\hat{\\beta}) = 0.3$, and we test the null hypothesis $H_0: \\beta = 0$.\n",
    "\n",
    "1. Compute the t-statistic:\n",
    "    $$\n",
    "    t = \\frac{\\hat{\\beta} - \\beta_0}{\\text{SE}(\\hat{\\beta})} = \\frac{1.2 - 0}{0.3} = 4.0.\n",
    "    $$\n",
    "\n",
    "2. Compare to the critical value: For $df = N - p$ and a $95\\%$ confidence level, the critical value $t^*$ might be approximately $2.0$ from the T-distribution table below:\n",
    "\n",
    "| **df**  | **$0.10$**    | **$0.05$**    | **$0.02$**    | **$0.01$**        | **$0.001$**        |  \n",
    "|---------|---------------|---------------|---------------|-------------------|--------------------|  \n",
    "| 1       | 6.314         | 12.706        | 31.821        | 63.657            | 636.619            |  \n",
    "| 2       | 2.920         | 4.303         | 6.965         | 9.925             | 31.599             |  \n",
    "| 3       | 2.353         | 3.182         | 4.541         | 5.841             | 12.924             |  \n",
    "| 4       | 2.132         | 2.776         | 3.747         | 4.604             | 8.610              |  \n",
    "| 5       | 2.015         | 2.571         | 3.365         | 4.032             | 6.869              |  \n",
    "| 10      | 1.812         | 2.228         | 2.764         | 3.169             | 4.587              |  \n",
    "| 20      | 1.725         | 2.086         | 2.528         | 2.845             | 3.850              |  \n",
    "| 30      | 1.697         | 2.042         | 2.457         | 2.750             | 3.646              |  \n",
    "| 40      | 1.684         | 2.021         | 2.423         | 2.704             | 3.551              |  \n",
    "| ‚àû       | 1.645         | 1.960         | 2.326         | 2.576             | 3.291              |  \n",
    "\n",
    "\n",
    "- Find the row corresponding to your degrees of freedom ($\\text{df} = N - p$).\n",
    "- Select the column corresponding to your desired significance level ($\\alpha$).\n",
    "- Compare your calculated $t$-statistic to the critical value:\n",
    "     - If $|t| > t^*$, reject the null hypothesis.\n",
    "     - If $|t| \\leq t^*$, fail to reject the null hypothesis.\n",
    "\n",
    "For example:\n",
    "- If $df = 10$, the critical value $t^* = 2.228$.\n",
    "- If $df = 30$, the critical value $t^* = 2.042$.\n",
    "- As $df \\to \\infty$, the T-distribution converges to the standard normal distribution with $t^* = 1.960$.\n",
    "\n",
    "3. Make a decision: Since $|4.0| > 2.0$, we reject $H_0$ and conclude that $\\beta \\neq 0$.\n",
    "\n",
    "By applying the t-test, we determine whether $\\hat{\\beta}$ provides evidence of a significant relationship between $X$ and $Y$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = Y-X*bhat\n",
    "s =  np.sum(resid**2)/(N-1)\n",
    "var = s/(np.sum(X**2))\n",
    "\n",
    "se = np.sqrt(var)\n",
    "\n",
    "# Create Figure\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.scatter(Y,X, alpha = 0.4, color = 'red')\n",
    "ax.plot(Yhat,X, color = 'blue')\n",
    "\n",
    "ax.set_xlabel('Independent variable (X)')\n",
    "ax.set_ylabel('Dependent variable (Y)')\n",
    "ax.set_title(r'Proposed DGP with $\\beta$='+str(beta),size=20)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.annotate(fr'$\\hat\\beta=${bhat:.2f} ({se:.4f})', (1.6,3.5),size=16, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, we can see that our simple linear model replicates the data well and -- since we know the true DGP -- also recovers the true value of $\\beta$. \n",
    "\n",
    "In our simple example we only included on variable and therefore only solved for one coefficient. Going forward, our data will be much more complicated (e.g., more independent X variables) and we'll want to account for the possibility that our dependent variable attains some value independent of the observed X variables in our data -- we'll want to include a constant in our $f()$ specification. It turns out that doing all of this is pretty straight-forward and the intution gained from our simple example extends easilly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Task #3</font>\n",
    "\n",
    "1. Increase N to $\\{200,500,1000\\}$. What happens to the estimated coefficient $(\\hat\\beta)$ and the estimated standard errors $(\\hat \\epsilon)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Change the specification by changing $\\beta$ to a value of your choice and re-run the code to find $\\hat\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Multivariate OLS Regression  ([top](#home))<a id=\"ols\"></a>\n",
    "\n",
    "Until now, we have worked on simple linear regression, which consists of analyzing the relationship between two variables: a dependent variable $Y$ and an independent variable $X$. While this method provides useful information, particularly in terms of methodology, real-world problems are much more complex and closely interrelated, requiring us to incorporate several factors simultaneously. Multivariate regression using ordinary least squares (OLS) allows us to extend the simple regression framework to include additional independent variables, giving us a better understanding of the relationships between the data.\n",
    "\n",
    "For example, after initially studying the effect of education on wages, new variables such as work experience, industry, and location can be added to the model to better isolate and interpret the influence of education. This extension involves adding additional terms to the regression equation:\n",
    "\n",
    "$$\n",
    "    Y = \\beta_0 + \\beta_1 X_1 +\\beta_2 X_2 +‚Ä¶+\\beta_k X_k+ \\epsilon\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $X_1,X_2,...,X_k$ are independent variables,\n",
    "- $\\beta_1, \\beta_2, ...,\\beta_k$ are their corresponding coefficients,\n",
    "- and $\\epsilon$ represents the error term.\n",
    "\n",
    "Multivariate regression makes it possible to answer questions such as *What is the effect of one variable, holding the others constant?‚Äô*\n",
    "\n",
    "### Which database?\n",
    "\n",
    "We will use examples from Wooldridge's popular textbook, *Introductory Econometrics: A Modern Approach*. This textbook is familiar to (almost) all students of econometrics.\n",
    "The data sets accompanying the textbook are readily available and, more importantly, already cleaned up. The only drawback is that they are supplied in STATA's .dta format.\n",
    "\n",
    "**Reading Stata files in Python**\n",
    "\n",
    "Fortunately, Python's `pandas` library provides the `read_stata` function, which allows us to import easily .dta files into Python. You'll find more details in the official [pandas.read_stata documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_stata.html).\n",
    "\n",
    "In addition to .dta files, pandas supports a wide range of file formats, including CSV, Excel, JSON, SQL, and SAS, making it an amazing versatile tool for data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Biddle and Hamermesh's model**\n",
    "\n",
    "Let's explore the relationship between labor wages and sleep using a 1990 paper by Biddle and Hamermesh ([link](https://www.jstor.org/stable/2937618?seq=1)). The authors use time-use data from 12 countries to examine whether an increase in wages leads individuals to sacrifice sleep.\n",
    "\n",
    "The basic idea is that people face time constraints. When wages increase, individuals may choose to sacrifice sleep to allocate more time to work and earn additional income. If we put this into a consumer optimization problem, then utility $U$ will depend on both sleep $s$ and consumption $c$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\max \\, & \\; U(\\underbrace{T-n}_{\\text{sleep}}, c) \\\\\n",
    "    \\text{s.t.} \\quad & T \\geq n + s, \\\\\n",
    "                              & \\underbrace{n\\cdot w}_{\\text{income}} \\geq \\underbrace{p\\cdot c}_{\\substack{\\text{money spent}\\\\ \\text{on consumption}}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "where:\n",
    "- $T$ is the total available time.\n",
    "- $n$ is the time spent working and $T-n$ the time spent sleeping\n",
    "- $c$ is the consumption of goods or services\n",
    "- $s$ is sleep time.\n",
    "- $w$ is the wage rate.\n",
    "- $p$ is the price of consumption goods.\n",
    "\n",
    "\n",
    "The utility is subject to two constraints:\n",
    "- $T‚â•n+s$: The total time $T$ must be at least equal to the sum of working time $n$ and sleeping time $s$.\n",
    "- $n\\cdot w \\geq p \\cdot c$: The income $w \\cdot n$ must cover the consumption cost $p \\cdot c$.\n",
    "\n",
    "The underlying idea behind this maximization is that people face time constraints. When wages rise, individuals may sacrifice sleep to spend more time at work and earn extra income. However, since total time $T$ is fixed, to increase worktime reduces sleeping time. While the authors want to show a causal link, ordinary least squares (OLS) regression will just reveal correlations.\n",
    "\n",
    "Let‚Äôs first load the dataset and have a look at the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>black</th>\n",
       "      <th>case</th>\n",
       "      <th>clerical</th>\n",
       "      <th>construc</th>\n",
       "      <th>educ</th>\n",
       "      <th>earns74</th>\n",
       "      <th>gdhlth</th>\n",
       "      <th>inlf</th>\n",
       "      <th>leis1</th>\n",
       "      <th>...</th>\n",
       "      <th>spwrk75</th>\n",
       "      <th>totwrk</th>\n",
       "      <th>union</th>\n",
       "      <th>worknrm</th>\n",
       "      <th>workscnd</th>\n",
       "      <th>exper</th>\n",
       "      <th>yngkid</th>\n",
       "      <th>yrsmarr</th>\n",
       "      <th>hrwage</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3529</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3438</td>\n",
       "      <td>0</td>\n",
       "      <td>3438</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>7.070004</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2140</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5020</td>\n",
       "      <td>0</td>\n",
       "      <td>5020</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429999</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4595</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2815</td>\n",
       "      <td>0</td>\n",
       "      <td>2815</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.529997</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3211</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3786</td>\n",
       "      <td>0</td>\n",
       "      <td>3786</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.619998</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4052</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>0</td>\n",
       "      <td>2580</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  black  case  clerical  construc  educ  earns74  gdhlth  inlf  leis1  \\\n",
       "0   32      0     1       0.0       0.0    12      0.0       0     1   3529   \n",
       "1   31      0     2       0.0       0.0    14   9500.0       1     1   2140   \n",
       "2   44      0     3       0.0       0.0    17  42500.0       1     1   4595   \n",
       "3   30      0     4       0.0       0.0    12  42500.0       1     1   3211   \n",
       "4   64      0     5       0.0       0.0    14   2500.0       1     1   4052   \n",
       "\n",
       "   ...  spwrk75  totwrk  union  worknrm  workscnd  exper  yngkid  yrsmarr  \\\n",
       "0  ...        0    3438      0     3438         0     14       0       13   \n",
       "1  ...        0    5020      0     5020         0     11       0        0   \n",
       "2  ...        1    2815      0     2815         0     21       0        0   \n",
       "3  ...        1    3786      0     3786         0     12       0       12   \n",
       "4  ...        1    2580      0     2580         0     44       0       33   \n",
       "\n",
       "      hrwage  agesq  \n",
       "0   7.070004   1024  \n",
       "1   1.429999    961  \n",
       "2  20.529997   1936  \n",
       "3   9.619998    900  \n",
       "4   2.750000   4096  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pandas read_stata method to get the stata formatted data file into a DataFrame.\n",
    "sleep = pd.read_stata('Tutorial_Python_20_OLS/SLEEP75.DTA')\n",
    "\n",
    "# Take a look!\n",
    "sleep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains the following variables:\n",
    "\n",
    "| Variable | Description | Variable | Description | Variable | Description |Variable | Description |\n",
    "| :------: | :---------- | :------: | :---------- |:-------: | :---------- |:------: | :---------- |\n",
    "|**age**   | ¬†in years\t |**leis1**\t|sleep - totwrk\t | \t**rlxall**\t | \t¬†slpnaps + personal activs\t | \t**worknrm**\t | \t¬†mins work main job\t | \n",
    " | \t**black**\t | \t¬†=1 if black\t | \t**leis2**\t | \t¬†slpnaps - totwrk\t | \t**selfe**\t | \t¬†=1 if self employed\t | \t**workscnd**\t | \t¬†mins work second job\t | \n",
    " | \t**case**\t | \t¬†identifier\t | \t**leis3**\t | \t¬†rlxall - totwrk\t | \t**sleep**\t | \t¬†mins sleep at night, per wk\t | \t**exper**\t | \t¬†age - educ - 6\t | \n",
    " | \t**clerical**\t | \t¬†=1 if clerical worker\t | \t**smsa**\t | \t¬†=1 if live in smsa\t | \t**slpnaps**\t | \t¬†minutes sleep, inc. naps\t | \t**yngkid**\t | \t¬†=1 if children < 3 present\t | \n",
    " | \t**construc**\t | \t¬†=1 if construction worker\t | \t**lhrwage**\t | \t¬†log hourly wage\t | \t**south**\t | \t¬†=1 if live in south\t | \t**yrsmarr**\t | \t¬†years married\t | \n",
    " | \t**educ**\t | \t¬†years of schooling\t | \t**lothinc**\t | \t¬†log othinc, unless othinc < 0\t | \t**spsepay**\t | \t¬†spousal wage income\t | \t**hrwage**\t | \t¬†hourly wage\t | \n",
    " | \t**earns74**\t | \t¬†total earnings, 1974\t | \t**male**\t | \t¬†=1 if male\t | \t**spwrk75**\t | \t¬†=1 if spouse works\t | \t**agesq**\t | \t¬†age^2\t | \n",
    " | \t**gdhlth**\t | \t¬†=1 if in good or excel. health\t | \t**marr**\t | \t¬†=1 if married\t | \t**totwrk**\t | \t¬†mins worked per week\t | \t\t\t\t\n",
    " | \t**inlf**\t | \t¬†=1 if in labor force\t | \t**prot**\t | \t¬†=1 if Protestant\t | \t**union**\t | \t¬†=1 if belong to union\t | \t\t\t\t\n",
    "\n",
    " \n",
    "### Data statistics\n",
    "\n",
    "Before conducting regression analysis, we have to explore the dataset. We examine key statistics for each variable - such as minimum, maximum, mean, standard deviation and number of observations - to gain valuable information about the characteristics of the data. This step helps us to :\n",
    "- Detect outliers or errors: Extreme values or inconsistencies can distort our analysis, so identifying them early is crucial.\n",
    "- View variability: The spread of variables via standard deviation helps us interpret regression results later. For example, if `sleep` has very little variation, it can be harder to explain differences using predictors.\n",
    "- Prepare for model selection: Summary statistics highlight relationships or patterns in the data that can guide hypothesis formulation and variable selection.\n",
    "- Check data completeness: Ensuring no significant portion of data is missing avoids biases in subsequent analyses.\n",
    "\n",
    "Now, we calculate these statistics and carefully interpret what they reveal about our dataset. To generate summary statistics, we use the pandas library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              age       black        case    clerical    construc        educ  \\\n",
      "count  706.000000  706.000000  706.000000  706.000000  706.000000  706.000000   \n",
      "mean    38.815864    0.049575  353.500000    0.182331    0.030075   12.780453   \n",
      "std     11.342637    0.217219  203.948932    0.335413    0.148366    2.784702   \n",
      "min     23.000000    0.000000    1.000000    0.000000    0.000000    1.000000   \n",
      "25%     29.000000    0.000000  177.250000    0.000000    0.000000   12.000000   \n",
      "50%     36.000000    0.000000  353.500000    0.000000    0.000000   12.000000   \n",
      "75%     48.000000    0.000000  529.750000    0.182331    0.030075   16.000000   \n",
      "max     65.000000    1.000000  706.000000    1.000000    1.000000   17.000000   \n",
      "\n",
      "            earns74      gdhlth        inlf        leis1  ...     spwrk75  \\\n",
      "count    706.000000  706.000000  706.000000   706.000000  ...  706.000000   \n",
      "mean    9767.705078    0.890935    0.753541  4690.723796  ...    0.480170   \n",
      "std     9323.587891    0.311942    0.431254   908.049561  ...    0.499961   \n",
      "min        0.000000    0.000000    0.000000  1745.000000  ...    0.000000   \n",
      "25%     2500.000000    1.000000    1.000000  4109.750000  ...    0.000000   \n",
      "50%     8250.000000    1.000000    1.000000  4620.000000  ...    0.000000   \n",
      "75%    13750.000000    1.000000    1.000000  5203.750000  ...    1.000000   \n",
      "max    42500.000000    1.000000    1.000000  7417.000000  ...    1.000000   \n",
      "\n",
      "            totwrk       union      worknrm     workscnd       exper  \\\n",
      "count   706.000000  706.000000   706.000000   706.000000  706.000000   \n",
      "mean   2122.920680    0.218130  2093.252125    29.668555   20.035411   \n",
      "std     947.470123    0.413269   945.301457   148.834262   12.377520   \n",
      "min       0.000000    0.000000     0.000000     0.000000    0.000000   \n",
      "25%    1553.500000    0.000000  1538.000000     0.000000   10.000000   \n",
      "50%    2288.000000    0.000000  2275.000000     0.000000   17.000000   \n",
      "75%    2691.750000    0.000000  2635.500000     0.000000   30.000000   \n",
      "max    6415.000000    1.000000  6415.000000  1337.000000   55.000000   \n",
      "\n",
      "           yngkid     yrsmarr      hrwage        agesq  \n",
      "count  706.000000  706.000000  532.000000   706.000000  \n",
      "mean     0.128895   11.769122    5.082839  1635.144476  \n",
      "std      0.335321   11.591227    3.704384   950.102976  \n",
      "min      0.000000    0.000000    0.350000   529.000000  \n",
      "25%      0.000000    0.000000    2.890002   841.000000  \n",
      "50%      0.000000    9.000000    4.379999  1296.000000  \n",
      "75%      0.000000   20.000000    6.210001  2304.000000  \n",
      "max      1.000000   43.000000   35.509987  4225.000000  \n",
      "\n",
      "[8 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume 'sleep' is the dataset loaded as a pandas DataFrame\n",
    "print(sleep.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sleep` is our dataset stored as a pandas DataFrame. It contains variables such as `totwrk` (hours worked), `educ` (years of education), and `age` (age in years), along with the dependent variable sleep.\n",
    "\n",
    "The `.describe()` method provides a summary for each numeric column, including:\n",
    "- `coun`: Number of non-missing observations.\n",
    "- `mean`: Average value of the variable.\n",
    "- `std`: Standard deviation, showing the variability of the data.\n",
    "- `min` and `max`: Smallest and largest observed values.\n",
    "- Quartiles (`25%`, `50%`, `75%`): Provide insights into the distribution of the data.\n",
    "\n",
    "This method provides us with a quick overview of the dataset, highlighting key characteristics and possible irregularities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An econometric model\n",
    "\n",
    "From an econometric perspective, the trade-off between sleep and work can be tested empirically by estimating the relationship between time spent working and time spent sleeping while controlling for other factors such as education and age that are available.\n",
    "\n",
    "For instance, we consider the following model:\n",
    "$$\n",
    "sleep=\\beta_0+\\beta_1 \\cdot totwrk+\\beta_2 \\cdot educ+\\beta_3 \\cdot age+\\epsilon\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $sleep$ is the time of sleep (dependent variable in min.),\n",
    "- $totwrk$ is the total time worked per week (in min.),\n",
    "- $educ$ is the number of years of education,\n",
    "- $age$ is the age of the individual,\n",
    "- $\\beta_0$ is the intercept or constant term,\n",
    "- $\\beta_1$, $\\beta_2$, and $\\beta_3$ are the coefficients for the independent variables,\n",
    "- $\\epsilon$ is the error term capturing variation unexplained by the model.\n",
    "\n",
    "We selected variables from all those available to build our model. In the utility framework, individuals make decisions that balance the trade-off between maximizing sleep (a component of utility) and earning income through work (to finance consumption). This theoretical model provides the basis for the empirical regression. The coefficients in the regression ($\\beta_1$, $\\beta_2$, $\\beta_3$) measure the marginal impact of work time, education, and age on sleep. For example:\n",
    "- $\\beta_1<0$ would suggest that more work reduces sleep, which would be consistent with the trade-off involved in the utility maximisation problem.\n",
    "- $\\beta_2<0$ and $\\beta_3$ capture additional socioeconomic factors influencing sleep.\n",
    "\n",
    "This econometric approach allows us to quantify the relationship between these variables and test hypotheses derived from the theoretical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing models with patsy\n",
    "In econometrics, a clear and efficient model is crucial, especially when dealing with multiple variables, transformations, or categorical data. The `patsy` package in Python is designed to simplify this process by providing a formal syntax for defining econometric models, very similar to the syntax used in R. Using `patsy`, we can describe models using strings. The basic syntax is:\n",
    "```\n",
    "y ~ x1 + x2\n",
    "```\n",
    "\n",
    "This corresponds to the model \n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon,$$\n",
    "\n",
    "where $y$ is the dependent variable, $x_1$ and $x_2$ are independent variables, $\\beta_0$ is the constant (automatically added by `patsy`), and $\\epsilon$ is the error term.\n",
    "\n",
    "One of the key advantages of `patsy` is that it automatically includes the constant term unless specified otherwise and supports more complex specifications like interactions, polynomial terms, and encoding categorical variables. It allows for a structured and concise definition of econometric models, enabling us to focus on data and results rather than on manual model setup.\n",
    "\n",
    "Let‚Äôs start slow and build up the regression step-by-step, then see how to define it all in one shot. Before we begin, ensure you have `patsy` installed by running:\n",
    "```python\n",
    "pip install patsy\n",
    "```\n",
    "\n",
    "To define our econometric model in Python, we have to create *design matrices* ‚Äî a term used to describe the matrices of independent variables (features) and the dependent variable (outcome). This is done by passing our model specification, written as a `patsy` formula string, to the function `patsy.dmatrices()`.\n",
    "\n",
    "The corresponding `patsy` formula string for our model defined above is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy                           # provides a syntax for specifying models  \n",
    "\n",
    "# Pass the model formula and the associated data to create design matrices\n",
    "y, X = patsy.dmatrices('sleep ~ totwrk + educ + age', sleep)\n",
    "\n",
    "# What do we have?\n",
    "print('X and y are of type:' , type(X), type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code explaination**\n",
    "\n",
    "`patsy.dmatrices` function:\n",
    "- Two main inputs:\n",
    "    - Model formula (`sleep ~ totwrk + educ + age`): This specifies the dependent variable `y` (sleep) and the independent variables `X` (`totwrk`, `educ`, `age`). The `~` separates the dependent and independent variables. The formula tells patsy to regress `sleep` on `totwrk`, `educ`, and `age`.\n",
    "    - Data input (`sleep): This should be a pandas DataFrame or dictionary containing the relevant variables as columns. patsy extracts the required variables from this data based on the formula.\n",
    "- Outputs:\n",
    "    - X: The design matrix for the independent variables (`totwrk`, `educ`, `age`), including an intercept column added automatically.\n",
    "    - y: The dependent variable (`sleep`) as a structured design matrix.\n",
    "\n",
    "Let's have a look at the two outputs $X$ and $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'sleep' is the dataset loaded as a pandas DataFrame\n",
    "print(sleep.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `X` contains the independent variables and `y` the dependent variable. Note that the intercept has been added (the ones column) to the `X` matrix.\n",
    "\n",
    "### Building and estimating the model in `statsmodels`\n",
    "\n",
    "With the design matrices in-hand, we can build **ordinary least squares (OLS)** model in the python package `statsmodels` which you can install via:\n",
    "\n",
    "```python\n",
    "pip install statsmodels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm           # provides statistical models like ols, gmm, anova, etc...\n",
    "\n",
    "# Pass design matrices to OLS to specifyan OLS model\n",
    "sleep_model = sm.OLS(y, X)\n",
    "type(sleep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now estimate the model using the `.fit( )` method of the statsmodel object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sleep_model.fit()  # Estimate the model and store the results in res\n",
    "\n",
    "# To see the summary report\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table presents the results of an Ordinary Least Squares (OLS) regression, which attempts to explain how `sleep` is influenced by work hours (`totwrk`), education (`educ`), and age (`age`). Let‚Äôs break it down step by step in a way that assumes no prior econometric knowledge but some familiarity with economics.\n",
    "\n",
    "**Overview of the table**\n",
    "- Dependent variable: The regression aims to predict `sleep` based on `totwrk`, `educ` and `age`\n",
    "- R-squared (0.113): About 11.3% of the variation in `sleep` can be explained by the variables `totwrk`, `educ` and `age`. This number shows how well the model fits the data. A higher value means better explanatory power.\n",
    "\n",
    "**Detailed explanation**\n",
    "\n",
    "1. Coefficients: Each coefficient tells us the estimated impact of the variable on sleep\n",
    "- Intercept ($3638.2453$): Predicted amount of sleep (in min.) when all explanatory variables (totwrk,educ,age) are zero. Since it's rare for someone to have zero work hours, education, or age, this value is less interpretable directly but anchors the regression line.\n",
    "- `totwrk` ($-0.1484$): For an additional hour worked, sleep decreases by approximately $0.148 \\times 60 \\sim 8.9$ min., assuming other variables remain constant.\n",
    "    - Significance: The p-value (<0.001) indicates this relationship is highly statistically significant, meaning there‚Äôs strong evidence that more work is associated with less sleep.\n",
    "- `educ` ($-11.1338$): An additional year of education decreases sleep by about $11$ min., holding other variables constant.\n",
    "     - Significance: With a p-value of $0.059$, this is marginally significant, suggesting a weak or uncertain effect.\n",
    "- `age` ($2.1999$): An additional year of age is associated with an increase in sleep by about $2.2$ min.\n",
    "    - Significance: The p-value ($0.129$) suggests this relationship isn‚Äôt statistically significant, meaning we can‚Äôt confidently conclude that age affects sleep in this sample.\n",
    "\n",
    "2. Statistical indicators\n",
    "- F-statistic ($29.92$) and Prob (F-statistic): These test whether all the explanatory variables collectively have an effect on sleep. The very small p-value ($3.28 \\times 10‚àí18$) indicates that at least one variable significantly affects sleep.\n",
    "- Log-Likelihood ($-5263.1$), AIC ($1.053e+04$), BIC ($1.055e+04$): These are measures of model quality. Lower values generally indicate better fit but are harder to interpret intuitively.\n",
    "\n",
    "3. Diagnostics\n",
    "- Omnibus ($68.731$) and Jarque-Bera ($185.551$): These test whether the model's residuals (errors) are normally distributed. The small p-values suggest deviations from normality.\n",
    "- Durbin-Watson ($1.943$): This tests for autocorrelation in the residuals. A value near $2$ suggests no strong autocorrelation, which is good.\n",
    "- Condition Number ($1.66e+04$): A high number indicates potential multicollinearity (when variables are highly correlated, making estimates unstable). This may warrant further investigation.\n",
    "\n",
    "**Economic Interpretation:**\n",
    "- Time is limited: When people work more hours, they tend to sleep less. This aligns with economic reasoning about trade-offs in time allocation.\n",
    "- Education‚Äôs weak negative effect on sleep might reflect higher opportunity costs of time for more educated individuals.\n",
    "- Age‚Äôs weak positive effect suggests older individuals might prioritize rest more, though this isn‚Äôt statistically strong here.\n",
    "\n",
    "This analysis provides a quantitative way to test the idea that work reduces sleep. The p-values indicate which effects we can be confident in (e.g., work hours) and which require caution (e.g., education, age), and low R2 suggests the model could be improved by adding other relevant factors, such as health, income, or lifestyle habits.\n",
    "\n",
    "We can retrieve other results too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The estimated coefficients are:', res.params, '\\n')\n",
    "print('The confidence intervals are:\\n', res.conf_int(), '\\n')\n",
    "print(f'The r-squared is: {res.rsquared:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating models with formula.api\n",
    "Earlier, we manually built our model step by step:\n",
    "- Created the design matrices with patsy.\n",
    "- Defined the model with statsmodels.\n",
    "- Fitted the model and obtained results.\n",
    "\n",
    "While this process helped us understand the underlying steps, we can accomplish all of this in a single line of code. By passing the patsy formula and data directly to statsmodels, we can call `.fit()` to estimate the model.\n",
    "\n",
    "This streamlined approach uses the `statsmodels.formula.api`, which automatically interprets the formula and generates the design matrices for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf  # provides a way to directly spec models from formulas\n",
    "\n",
    "res = smf.ols('sleep ~ totwrk + educ + age', data=sleep).fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformations\n",
    "The patsy package simplifies various regression tasks, including handling interactions and other transformations of variables. Here, we‚Äôll explore one key transformation: interacting variables.\n",
    "\n",
    "\n",
    "#### Interacting variables\n",
    "To include interactions between two variables in a regression model, use the `*` operator in the formula. This operator not only creates the interaction term but also includes the main effects of the variables involved.\n",
    "\n",
    "For example, consider interacting education (`educ`) and age (`age`) in our regression model. The resulting equation is:\n",
    "\n",
    "$$\n",
    "sleep = \\beta_0 + \\beta_1 totwrk + \\beta_2 educ + \\beta_3 age + \\beta_4 age\\times educ + \\epsilon\n",
    "$$.\n",
    "\n",
    "where:\n",
    "- $age \\times educ$ is the interaction term, capturing how the effect of one variable changes depending on the level of the other.\n",
    "\n",
    "**Why study interaction?**\n",
    "Studying interaction terms allows us to uncover relationships in the data that would otherwise remain hidden in a standard linear model. Interaction terms help us understand how the effect of one variable depends on the level of another, making it possible to explore conditional effects. For instance, the relationship between education and sleep might vary across different age groups, revealing patterns that a simpler model might overlook.\n",
    "\n",
    "Including interaction terms also enables us to capture synergies or trade-offs between variables. In some cases, two variables may work together in a complementary or conflicting manner, and modeling these dynamics provides a more accurate representation of the underlying relationships. This leads to richer insights by highlighting nuances in the data. For example, while education alone might not have a strong effect on sleep, its interaction with age could uncover meaningful variations.\n",
    "\n",
    "Moreover, interaction terms improve the overall fit of a regression model by accounting for variability that is missed when only main effects are considered. By incorporating these terms, we go beyond simple linear relationships and achieve a deeper and more nuanced understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = smf.ols('sleep ~ totwrk + educ*age', data=sleep).fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using logs \n",
    "\n",
    "Logarithmic transformations, applied using `np.log()` in the patsy syntax, are valuable for stabilizing variance, reducing skewness, and linearizing relationships in regression models. For example, by including the logarithm of age as a predictor, we capture proportional relationships and interpret coefficients as percentage effects. This approach enhances both the model's accuracy and the interpretability of the results.\n",
    "\n",
    "We use the `np.log( )` method directly in the patsy syntax. Note that we loaded the numpy package above as np. Here, we use the logarithm of `age` in the model:\n",
    "\n",
    "$$\n",
    "sleep = \\beta_0 + \\beta_1 totwrk + \\beta_2 educ + \\beta_3 \\log(age)  + \\epsilon\n",
    "$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = smf.ols('sleep ~ totwrk + educ + np.log(age)', data=sleep).fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed effects\n",
    "**Fixed effects**, often referred to as dummy variables, allow us to account for categorical differences in a regression model. For instance, if `gender` is coded as ${0,1}$ with \"male\" represented as 1 and \"female\" as the reference group, the coefficient on the `gender` dummy indicates how men differ from women, holding other factors constant. A positive coefficient suggests that men sleep more than women, ceteris paribus. In this setup, the intercept represents the predicted value for the reference group‚Äîin this case, women. Fixed effects provide a simple yet powerful way to control for categorical variables in a regression framework.\n",
    "\n",
    "**Simple example**\n",
    "\n",
    "Suppose we want to understand how gender affects sleep, holding other factors constant. Here's a basic dataset:\n",
    "\n",
    " | Gender | Sleep (hours/week) | \n",
    " | :----: | :----------------- | \n",
    " |Female  |       ¬†50          |\n",
    " |Female  |       ¬†55          |\n",
    " |Male    |       ¬†60          |\n",
    " |Male    |       ¬†65          |\n",
    " \n",
    "\n",
    "We create a dummy variable for gender:  \n",
    "- Female = 0 (reference group)\n",
    "- Male = 1\n",
    "\n",
    "The regression equation becomes:  \n",
    "\n",
    "$$\n",
    "Sleep = \\beta_0 + \\beta_1 \\cdot Male + \\epsilon\n",
    "$$\n",
    "\n",
    "If we estimate this model, we might get:  \n",
    "- $\\beta_0 = 52.5$: intercept, average sleep for females\n",
    "- $\\beta_1 = 10$: difference in sleep for males relative to females\n",
    "\n",
    "Interpretation\n",
    "- Females: Predicted sleep = $52.5 + 10 \\cdot 0 = 52.5$ hrs/week (matches their average).\n",
    "- Males: Predicted sleep = $52.5 + 10 \\cdot 1 = 62.5$ hrs/week (matches their average).\n",
    "\\end{itemize}\n",
    "\n",
    "Here, the fixed effect for \"male\" adds 10 hours to the baseline sleep of females, showing that men sleep more than women, on average, in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sleep['gender'] = sleep['male'].replace({1.0:'male', 0.0:'female'})\n",
    "\n",
    "res = smf.ols('sleep ~ totwrk + educ + age + C(gender)', data=sleep).fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No intercept \n",
    "Use `-1` to kill the automatic intercept and force the regression to go through the origin (as in our simple example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = smf.ols('sleep ~ totwrk + educ + age + C(gender) -1', data=sleep).fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Practice </font>\n",
    "\n",
    "1. Load `wage1.dta`: http://qcpages.qc.cuny.edu/~rvesselinov/statafiles.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generate a scatter plot of log(wage) on education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What's the relationship between education and log-wage? Estimate<br><br>\n",
    "$$ \\log(wage) = \\beta_0 + \\beta_1 educ + \\epsilon$$<br>\n",
    "Print your estimated coefficient on education. Is it statistically significant from zero? What's the interpretation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scatter plot the residuals against education. The residuals are in the results object from the `fit` method. Use tab-completion to find them. Ideally, the residuals should look like a cloud. Do they in this regression? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Redo the estimation allowing for a more flexible variance-covariance matrix which is to say we'll allow for the errors to be more flexible. Try 'HC3' for your covariance matrix type. Your estimates shouldn't change but your standard errors will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Make a scatter plot of the data and add the regression line. To plot the regression line you will need to create some x data and then apply the parameters; e.g.,\n",
    "```python\n",
    "y = [p.Intercept + p.educ*i for i in educ]\n",
    "```\n",
    "where `p` holds the parameters from my results and `educ` holds the relavent independent variable from the specification. An alternative is to use seaborn's `regplot()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Go back and add the text 'log(w) = a + b*educ' to the northwest corner of your plot. Replace a and b with the estimated parameter values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Let's modify the regression to include education in logs.<br><br>\n",
    "$$ \\log(wage) = \\beta_0 + \\beta_1 \\log(educ)+\\epsilon$$<br>\n",
    "Estimate the model and interpret your results. You may have to drop a couple observations with where education is zero (or add a one to all education numbers in the data) in order to generate nice output.<br><br>**Hint:** Totall differentiate our specification to get $\\frac{dw}{w}=\\beta_1\\times\\frac{de}{e}$. Rearrange such that $\\beta_1 = \\frac{dw}{de}\\times \\frac{e}{w}.$ What is the economic term for the RHS of that expression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Let's add some additional regressors (aka RHS variables, independent variables, covariates). Estimate<br><br>\n",
    "$$ \\log(wage) = \\beta_0 + \\beta_1 educ + \\beta_2 exper + \\beta_3 exper^2 + \\beta_4I_m + \\epsilon$$<br>\n",
    "where $I_m$ is a variable equal to 1 if the worker is a married. Interpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
